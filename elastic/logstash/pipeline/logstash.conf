input {

  # stdin {}

  file {
    path => "/usr/share/logstash/monitor/*.log"
    start_position => "beginning"
  }

}
filter {

  # create hash from message to handle duplicates
  fingerprint {
    source => "message"
    target => "[@metadata][fingerprint]"
    method => "MURMUR3"
  }

  if [path] =~ "access" {
    

    mutate {
      add_field => { "[log][type]" => "access" }
    }
    
    grok {
      match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[@metadata][jwt]}\" \"%{DATA:[nginx][access][agent]}\" \"%{IPORHOST:[nginx][access][client_ip]}\" \"%{GREEDYDATA:[nginx][access][payload]}\""] }
      remove_field => "message"
    }
    mutate {
      add_field => { "read_timestamp" => "%{@timestamp}" }
    }
    date {
      match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
      remove_field => "[nginx][access][time]"
    }
    useragent {
      source => "[nginx][access][agent]"
      target => "[nginx][access][user_agent]"
      remove_field => "[nginx][access][agent]"
    }
    geoip {
      source => "[nginx][access][remote_ip]"
      target => "[nginx][access][geoip]"
    }

    geoip {
      source => "[nginx][access][client_ip]"
      target => "[nginx][access][server][geoip]"
    }


    # decode JWT
    if [@metadata][jwt] {

      mutate {
        split => { "[@metadata][jwt]" => "." }
      }

      mutate {
        copy => { "[@metadata][jwt][1]" => "[@metadata][b64]" }
      }

      ruby {
        init => "require 'base64'"
        code => "event.set('[@metadata][jwt_decoded]', Base64.decode64(event.get('[@metadata][b64]')))"
      }

      json {
        source => "[@metadata][jwt_decoded]"
        target => "jwt_data"
      }

    }

    if [nginx][access][payload] {
      # remove \ from payload
      mutate {
        gsub => [
          "[nginx][access][payload]", "[\\]", ""
        ]
      }

      # parse json to data field
      json {
        source => "[nginx][access][payload]"
        target => "[data]"
      }
    }


    # Get the type of operation of interest

    mutate {
      add_field => { "[@metadata][action]" => "%{[nginx][access][method]} %{[nginx][access][url]}" }
    }

    # Get the operation
    translate {
      field => "[@metadata][action]"
      destination => "operation"
      dictionary_path => "/usr/share/logstash/dictionaries/action.yml"
      fallback => "other"
      regex => true
    }

    # Extract mine guid based on operation
    if [operation] != "other" {
      grok {
        match => { "[nginx][access][url]" => [".*/api/mines/%{UUID:[mine][id]}", ".*/api/documents/mines/%{UUID:[mine][id]}"] }
      }

      # lookup by mine id
      translate {
        field => "[mine][id]"
        destination => "[@metadata][mine_json]"
        dictionary_path => "/usr/share/logstash/dictionaries/mine.lookup.yml"
        regex => true
      }

      if [@metadata][mine_json] {
        json {
          source => "[@metadata][mine_json]"
          target => "[mine_data]"
        }
      }

      if [nginx][access][referrer] {
        translate {
          field => "[nginx][access][referrer]"
          destination => "[mds][group]"
          dictionary_path => "/usr/share/logstash/dictionaries/group.yml"
          regex => true
          fallback => 'other'
          exact => true
        }
      }

    }
  }
  else if [path] =~ "error" {

    mutate {
      add_field => { "[log][type]" => "error" }
    }

    grok {
      match => { "message" => ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
      remove_field => "message"
    }
    mutate {
      rename => { "@timestamp" => "read_timestamp" }
    }
    date {
      match => [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
      remove_field => "[nginx][error][time]"
    }
  }
}


output {
  
  # stdout {}

  elasticsearch {
    hosts => "${ES_HOST}"
    user => "${ES_USER}"
    password => "${ES_PASSWORD}"
    index => "mds-nginx-%{[log][type]}-%{+YYYY.MM.dd}"
    document_id => "%{[@metadata][fingerprint]}"
    template => "/usr/share/logstash/templates/mds.nginx.template.json"
    template_name => "mds-nginx"
  }

}